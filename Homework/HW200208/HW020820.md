---
title: "HW020820"
output: 
  html_document:
    keep_md: TRUE
    toc: TRUE
    toc_float: TRUE
---



##Chapter 3

###Conceptual

####Q1

The advertising budgets of `TV`, `radio`, and `newspaper` don't have an influence on `sales`. The p-values for `TV` and `radio` are significant, while that for `newspaper` is not, meaning we can reject null hypothesis for `TV` and `radio`. So `TV` and `radio` budgets have a significant impact on `sales`.

####Q2

KNN classifier: qualitative response; KNN regression: quantitative response.

####Q3

`y=50+20GPA+0.07IQ+35Gender+0.01GPA*IQ-10GPA*Gender`

a) iii is correct
b) `50+20*4+0.07*110+35+0.01*110*4.0=137.1` ==> $137100
c) false. To see if there is an interaction we need to check the p-value

####Q4

a) Because the actual relationship is linear, the linear regression might have a lower RSS compared to the cubic regression.
b) Cubic regression might have a higher RSS because overfitting leads to more errors.
c) Cubic regression might have a lower RSS because it is more flexible.
d) we don't know

####Q5

`a_i=(x_ix_j)/(\sum x^2)`

####Q6

`y=b0+b1x`
`y=b0+b1x_bar=(y_bar-b1*x_bar)+b1*x_bar=y_bar`

####Q7

Substitute the definition of RSS and TSS into the expression of R^2 (R^2=1-RSS/TSS), then ultimately find that `R^2=(\sum xi^2*yi^2)/((\sum xj^2)(\sum yj^2))=CoR(X, Y)^2`

###Applied

####Q8


```r
mpg_power <- lm(mpg~horsepower, Auto)
summary(mpg_power)
```

```
## 
## Call:
## lm(formula = mpg ~ horsepower, data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -13.5710  -3.2592  -0.3435   2.7630  16.9240 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 39.935861   0.717499   55.66   <2e-16 ***
## horsepower  -0.157845   0.006446  -24.49   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.906 on 390 degrees of freedom
## Multiple R-squared:  0.6059,	Adjusted R-squared:  0.6049 
## F-statistic: 599.7 on 1 and 390 DF,  p-value: < 2.2e-16
```

i) yes, F-statistic is much larger than 1 and p-value is very small
ii) according to the R^2 value, it means aroung 60% of the variation in mpg can be explained by variation in the horsepower.
iii) the coefficient is -0.1578, so it's negative.
iv) 

```r
predict(mpg_power, data.frame(horsepower = 98), interval = "confidence")
```

```
##        fit      lwr      upr
## 1 24.46708 23.97308 24.96108
```


```r
predict(mpg_power, data.frame(horsepower = 98), interval = "prediction")
```

```
##        fit     lwr      upr
## 1 24.46708 14.8094 34.12476
```

b)

```r
plot(Auto$horsepower, Auto$mpg)
abline(mpg_power, col = "red")
```

![](HW020820_files/figure-html/unnamed-chunk-4-1.png)<!-- -->

c)

```r
plot(mpg_power)
```

![](HW020820_files/figure-html/unnamed-chunk-5-1.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-5-2.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-5-3.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-5-4.png)<!-- -->

The residuals vs. fitted plot means the relationship is non-linear; residuals vs. leverage implies a few outliers (|y|>2) and some high leverage points.

####Q9


```r
pairs(Auto)
```

![](HW020820_files/figure-html/unnamed-chunk-6-1.png)<!-- -->

b) 

```r
glimpse(Auto)
```

```
## Observations: 392
## Variables: 9
## $ mpg          <dbl> 18, 15, 18, 16, 17, 15, 14, 14, 14, 15, 15, 14, 1...
## $ cylinders    <dbl> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 6, 6...
## $ displacement <dbl> 307, 350, 318, 304, 302, 429, 454, 440, 455, 390,...
## $ horsepower   <dbl> 130, 165, 150, 150, 140, 198, 220, 215, 225, 190,...
## $ weight       <dbl> 3504, 3693, 3436, 3433, 3449, 4341, 4354, 4312, 4...
## $ acceleration <dbl> 12.0, 11.5, 11.0, 12.0, 10.5, 10.0, 9.0, 8.5, 10....
## $ year         <dbl> 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 7...
## $ origin       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1...
## $ name         <fct> chevrolet chevelle malibu, buick skylark 320, ply...
```


```r
cor(Auto[-9])
```

```
##                     mpg  cylinders displacement horsepower     weight
## mpg           1.0000000 -0.7776175   -0.8051269 -0.7784268 -0.8322442
## cylinders    -0.7776175  1.0000000    0.9508233  0.8429834  0.8975273
## displacement -0.8051269  0.9508233    1.0000000  0.8972570  0.9329944
## horsepower   -0.7784268  0.8429834    0.8972570  1.0000000  0.8645377
## weight       -0.8322442  0.8975273    0.9329944  0.8645377  1.0000000
## acceleration  0.4233285 -0.5046834   -0.5438005 -0.6891955 -0.4168392
## year          0.5805410 -0.3456474   -0.3698552 -0.4163615 -0.3091199
## origin        0.5652088 -0.5689316   -0.6145351 -0.4551715 -0.5850054
##              acceleration       year     origin
## mpg             0.4233285  0.5805410  0.5652088
## cylinders      -0.5046834 -0.3456474 -0.5689316
## displacement   -0.5438005 -0.3698552 -0.6145351
## horsepower     -0.6891955 -0.4163615 -0.4551715
## weight         -0.4168392 -0.3091199 -0.5850054
## acceleration    1.0000000  0.2903161  0.2127458
## year            0.2903161  1.0000000  0.1815277
## origin          0.2127458  0.1815277  1.0000000
```

c)

```r
fit_all <- lm(mpg~ .-name, Auto)
summary(fit_all)
```

```
## 
## Call:
## lm(formula = mpg ~ . - name, data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.5903 -2.1565 -0.1169  1.8690 13.0604 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -17.218435   4.644294  -3.707  0.00024 ***
## cylinders     -0.493376   0.323282  -1.526  0.12780    
## displacement   0.019896   0.007515   2.647  0.00844 ** 
## horsepower    -0.016951   0.013787  -1.230  0.21963    
## weight        -0.006474   0.000652  -9.929  < 2e-16 ***
## acceleration   0.080576   0.098845   0.815  0.41548    
## year           0.750773   0.050973  14.729  < 2e-16 ***
## origin         1.426141   0.278136   5.127 4.67e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.328 on 384 degrees of freedom
## Multiple R-squared:  0.8215,	Adjusted R-squared:  0.8182 
## F-statistic: 252.4 on 7 and 384 DF,  p-value: < 2.2e-16
```
i) yes, the F-statistic is far larger than 7 and p-value is very small. 
ii) displacemnet, weight, year, and origin
iii) an increase of 1 year correspond to 0.751 of increase in mpg. cars are getting more and more efficient very year.

d) 

```r
plot(fit_all)
```

![](HW020820_files/figure-html/unnamed-chunk-10-1.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-10-2.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-10-3.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-10-4.png)<!-- -->
A mild non-linearity, some outliers, and one high leverage point (14). 

e)

```r
inter <- lm(mpg~cylinders*horsepower, Auto)
summary(inter)
```

```
## 
## Call:
## lm(formula = mpg ~ cylinders * horsepower, data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.5862  -2.1945  -0.5617   1.9541  16.3329 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)          72.815097   3.071314  23.708   <2e-16 ***
## cylinders            -6.492462   0.510560 -12.716   <2e-16 ***
## horsepower           -0.416007   0.034521 -12.051   <2e-16 ***
## cylinders:horsepower  0.047247   0.004732   9.984   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.094 on 388 degrees of freedom
## Multiple R-squared:  0.727,	Adjusted R-squared:  0.7249 
## F-statistic: 344.4 on 3 and 388 DF,  p-value: < 2.2e-16
```
yes, small p-value.

f)

```r
plot(log(Auto$horsepower), Auto$mpg)
```

![](HW020820_files/figure-html/unnamed-chunk-12-1.png)<!-- -->

```r
plot(sqrt(Auto$horsepower), Auto$mpg)
```

![](HW020820_files/figure-html/unnamed-chunk-12-2.png)<!-- -->

```r
plot((Auto$horsepower)^2, Auto$mpg)
```

![](HW020820_files/figure-html/unnamed-chunk-12-3.png)<!-- -->


```r
x <- lm(mpg~log(acceleration), Auto)
summary(x)
```

```
## 
## Call:
## lm(formula = mpg ~ log(acceleration), data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -18.0234  -5.6231  -0.9787   4.5943  23.0872 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        -27.834      5.373  -5.180 3.56e-07 ***
## log(acceleration)   18.801      1.966   9.565  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.033 on 390 degrees of freedom
## Multiple R-squared:   0.19,	Adjusted R-squared:  0.1879 
## F-statistic: 91.49 on 1 and 390 DF,  p-value: < 2.2e-16
```


```r
y <- lm(mpg~sqrt(acceleration), Auto)
summary(y)
```

```
## 
## Call:
## lm(formula = mpg ~ sqrt(acceleration), data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -18.034  -5.601  -1.027   4.713  23.184 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(>|t|)    
## (Intercept)         -14.177      4.008  -3.537 0.000453 ***
## sqrt(acceleration)    9.582      1.017   9.424  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.053 on 390 degrees of freedom
## Multiple R-squared:  0.1855,	Adjusted R-squared:  0.1834 
## F-statistic: 88.81 on 1 and 390 DF,  p-value: < 2.2e-16
```


```r
z <- lm(mpg~acceleration^2, Auto)
summary(z)
```

```
## 
## Call:
## lm(formula = mpg ~ acceleration^2, data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -17.989  -5.616  -1.199   4.801  23.239 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)    4.8332     2.0485   2.359   0.0188 *  
## acceleration   1.1976     0.1298   9.228   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.08 on 390 degrees of freedom
## Multiple R-squared:  0.1792,	Adjusted R-squared:  0.1771 
## F-statistic: 85.15 on 1 and 390 DF,  p-value: < 2.2e-16
```

####Q10


```r
seats <- lm(Sales~ Price + Urban + US, Carseats)
summary(seats)
```

```
## 
## Call:
## lm(formula = Sales ~ Price + Urban + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9206 -1.6220 -0.0564  1.5786  7.0581 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 13.043469   0.651012  20.036  < 2e-16 ***
## Price       -0.054459   0.005242 -10.389  < 2e-16 ***
## UrbanYes    -0.021916   0.271650  -0.081    0.936    
## USYes        1.200573   0.259042   4.635 4.86e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.472 on 396 degrees of freedom
## Multiple R-squared:  0.2393,	Adjusted R-squared:  0.2335 
## F-statistic: 41.52 on 3 and 396 DF,  p-value: < 2.2e-16
```

b)
The average effect of a price increase of 1 dollar is a decrease of 0.054459 unit in sales while all other predictors remaining fixed.
On average, the unit sales in urban location are 21.9161508 units less than in rural location all other predictors remaining fixed.
On average the unit sales in a US store are 1200.5726978 units more than in a non US store all other predictors remaining fixed.

c) Sales=13.0434689+(???0.0544588)??Price+(???0.0219162)??Urban+(1.2005727)??US+??
d) Price and US
e) 

```r
priceus <- lm(Sales ~ Price + US, data = Carseats)
summary(priceus)
```

```
## 
## Call:
## lm(formula = Sales ~ Price + US, data = Carseats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9269 -1.6286 -0.0574  1.5766  7.0515 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 13.03079    0.63098  20.652  < 2e-16 ***
## Price       -0.05448    0.00523 -10.416  < 2e-16 ***
## USYes        1.19964    0.25846   4.641 4.71e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.469 on 397 degrees of freedom
## Multiple R-squared:  0.2393,	Adjusted R-squared:  0.2354 
## F-statistic: 62.43 on 2 and 397 DF,  p-value: < 2.2e-16
```
f) R62 of the smaller model is a bit better than for the bigger one.
g)

```r
confint(priceus)
```

```
##                   2.5 %      97.5 %
## (Intercept) 11.79032020 14.27126531
## Price       -0.06475984 -0.04419543
## USYes        0.69151957  1.70776632
```
h)

```r
plot(priceus)
```

![](HW020820_files/figure-html/unnamed-chunk-19-1.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-19-2.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-19-3.png)<!-- -->![](HW020820_files/figure-html/unnamed-chunk-19-4.png)<!-- -->

####Q11


```r
set.seed(1)
x <- rnorm(100)
y <- 2 * x + rnorm(100)
```
 

```r
fit <- lm(y ~ x + 0)
summary(fit)
```

```
## 
## Call:
## lm(formula = y ~ x + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.9154 -0.6472 -0.1771  0.5056  2.3109 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(>|t|)    
## x   1.9939     0.1065   18.73   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.9586 on 99 degrees of freedom
## Multiple R-squared:  0.7798,	Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: < 2.2e-16
```
we have a value of 1.9938761 for ???? , a value of 0.1064767 for the standard error, a value of 18.7259319 for the t-statistic and a value of 2.642196910^{-34} for the p-value. The small p-value allows us to reject H0.

b)

```r
fit1 <- lm(x ~ y + 0)
summary(fit1)
```

```
## 
## Call:
## lm(formula = x ~ y + 0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.8699 -0.2368  0.1030  0.2858  0.8938 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(>|t|)    
## y  0.39111    0.02089   18.73   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4246 on 99 degrees of freedom
## Multiple R-squared:  0.7798,	Adjusted R-squared:  0.7776 
## F-statistic: 350.7 on 1 and 99 DF,  p-value: < 2.2e-16
```
we have a value of 0.3911145 for ???? , a value of 0.0208863 for the standard error, a value of 18.7259319 for the t-statistic and a value of 2.642196910^{-34} for the p-value. The small p-value allows us to reject H0.

c) We obtain the same value for the t-statistic and consequently the same value for the corresponding p-value. ?? values are reciprocal of each other.

d) 

```r
n <- length(x)
t <- sqrt(n - 1)*(x %*% y)/sqrt(sum(x^2) * sum(y^2) - (x %*% y)^2)
as.numeric(t)
```

```
## [1] 18.72593
```

e)
The t-statistics for the regression of y onto x is the same as that of x onto y.

f)

```r
fit2 <- lm(x ~ y)
summary(fit2)
```

```
## 
## Call:
## lm(formula = x ~ y)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.90848 -0.28101  0.06274  0.24570  0.85736 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  0.03880    0.04266    0.91    0.365    
## y            0.38942    0.02099   18.56   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4249 on 98 degrees of freedom
## Multiple R-squared:  0.7784,	Adjusted R-squared:  0.7762 
## F-statistic: 344.3 on 1 and 98 DF,  p-value: < 2.2e-16
```
the t-value stays the same with or without intercept.

####Q12

a) `beta = \sum(xiyi)/\sum(xi^2), beta' = \sum(xiyi)/\sum(yi^2)`
when sum of xi^2 equals the sum of yi^2.
b) 

```r
set.seed(1)
x <- 1:100
sum(x^2)
```

```
## [1] 338350
```

```r
y <- 2 * x + rnorm(100, sd = 0.1)
sum(y^2)
```

```
## [1] 1353606
```


```r
fit.Y <- lm(y ~ x + 0)
fit.X <- lm(x ~ y + 0)
summary(fit.Y)
```

```
## 
## Call:
## lm(formula = y ~ x + 0)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.223590 -0.062560  0.004426  0.058507  0.230926 
## 
## Coefficients:
##    Estimate Std. Error t value Pr(>|t|)    
## x 2.0001514  0.0001548   12920   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.09005 on 99 degrees of freedom
## Multiple R-squared:      1,	Adjusted R-squared:      1 
## F-statistic: 1.669e+08 on 1 and 99 DF,  p-value: < 2.2e-16
```

```r
summary(fit.X)
```

```
## 
## Call:
## lm(formula = x ~ y + 0)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.115418 -0.029231 -0.002186  0.031322  0.111795 
## 
## Coefficients:
##   Estimate Std. Error t value Pr(>|t|)    
## y 5.00e-01   3.87e-05   12920   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.04502 on 99 degrees of freedom
## Multiple R-squared:      1,	Adjusted R-squared:      1 
## F-statistic: 1.669e+08 on 1 and 99 DF,  p-value: < 2.2e-16
```

####Q13

a)

```r
set.seed(3)
x <- rnorm(100)
eps <- rnorm(100, sd = sqrt(0.25))
```
c) beta0 is -1, beta1 is 0.5

```r
y <- -1 + 0.5 * x + eps
length(y)
```

```
## [1] 100
```
d)

```r
plot(x, y)
```

![](HW020820_files/figure-html/unnamed-chunk-29-1.png)<!-- -->


```r
fit3 <- lm(y ~ x)
summary(fit3)
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.17999 -0.40785  0.01808  0.30911  1.31073 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.99003    0.05508 -17.975  < 2e-16 ***
## x            0.45492    0.06466   7.036 2.71e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.5507 on 98 degrees of freedom
## Multiple R-squared:  0.3356,	Adjusted R-squared:  0.3288 
## F-statistic: 49.51 on 1 and 98 DF,  p-value: 2.707e-10
```
Large F-statistic --> reject H0.
f)

```r
plot(x, y)
abline(fit3, col = "red")
abline(-1, 0.5, col = "blue")
legend("topleft", c("Least square", "Regression"), col = c("red", "blue"), lty = c(1, 1))
```

![](HW020820_files/figure-html/unnamed-chunk-31-1.png)<!-- -->
g) 

```r
fit4 <- lm(y ~ x + I(x^2))
summary(fit4)
```

```
## 
## Call:
## lm(formula = y ~ x + I(x^2))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.17343 -0.41256  0.00997  0.32449  1.33454 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -1.01850    0.07405 -13.754  < 2e-16 ***
## x            0.45832    0.06514   7.036 2.82e-10 ***
## I(x^2)       0.03917    0.06783   0.577    0.565    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.5526 on 97 degrees of freedom
## Multiple R-squared:  0.3379,	Adjusted R-squared:  0.3242 
## F-statistic: 24.75 on 2 and 97 DF,  p-value: 2.065e-09
```
the p value for x62 is large, so not significant.
h) less noise

```r
set.seed(1)
eps <- rnorm(100, sd = 0.125)
x <- rnorm(100)
y <- -1 + 0.5 * x + eps
plot(x, y)
fit5 <- lm(y ~ x)
summary(fit5)
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.29052 -0.07545  0.00067  0.07288  0.28664 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.98639    0.01129  -87.34   <2e-16 ***
## x            0.49988    0.01184   42.22   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1128 on 98 degrees of freedom
## Multiple R-squared:  0.9479,	Adjusted R-squared:  0.9474 
## F-statistic:  1782 on 1 and 98 DF,  p-value: < 2.2e-16
```

```r
abline(fit5, col = "red")
abline(-1, 0.5, col = "blue")
legend("topleft", c("Least square", "Regression"), col = c("red", "blue"), lty = c(1, 1))
```

![](HW020820_files/figure-html/unnamed-chunk-33-1.png)<!-- -->

i)

```r
set.seed(1)
eps <- rnorm(100, sd = 0.5)
x <- rnorm(100)
y <- -1 + 0.5 * x + eps
plot(x, y)
fit6 <- lm(y ~ x)
summary(fit6)
```

```
## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.16208 -0.30181  0.00268  0.29152  1.14658 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.94557    0.04517  -20.93   <2e-16 ***
## x            0.49953    0.04736   10.55   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4514 on 98 degrees of freedom
## Multiple R-squared:  0.5317,	Adjusted R-squared:  0.5269 
## F-statistic: 111.2 on 1 and 98 DF,  p-value: < 2.2e-16
```

```r
abline(fit6, col = "red")
abline(-1, 0.5, col = "blue")
legend("topleft", c("Least square", "Regression"), col = c("red", "blue"), lty = c(1, 1))
```

![](HW020820_files/figure-html/unnamed-chunk-34-1.png)<!-- -->

j)

```r
confint(fit3)
```

```
##                  2.5 %     97.5 %
## (Intercept) -1.0993336 -0.8807362
## x            0.3266109  0.5832237
```

```r
confint(fit5)
```

```
##                 2.5 %     97.5 %
## (Intercept) -1.008805 -0.9639819
## x            0.476387  0.5233799
```

```r
confint(fit6)
```

```
##                  2.5 %     97.5 %
## (Intercept) -1.0352203 -0.8559276
## x            0.4055479  0.5935197
```

more noise --> bigger interval

####Q14


```r
set.seed(1)
x1 <- runif(100)
x2 <- 0.5 * x1 + rnorm(100)/10
y <- 2 + 2 * x1 + 0.3 * x2 + rnorm(100)
```

correlation between x1 and x2:

```r
cor(x1, x2)
```

```
## [1] 0.8351212
```

```r
plot(x1, x2)
```

![](HW020820_files/figure-html/unnamed-chunk-37-1.png)<!-- -->


```r
collinear <- lm(y ~ x1 + x2)
summary(collinear)
```

```
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8311 -0.7273 -0.0537  0.6338  2.3359 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.1305     0.2319   9.188 7.61e-15 ***
## x1            1.4396     0.7212   1.996   0.0487 *  
## x2            1.0097     1.1337   0.891   0.3754    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.056 on 97 degrees of freedom
## Multiple R-squared:  0.2088,	Adjusted R-squared:  0.1925 
## F-statistic:  12.8 on 2 and 97 DF,  p-value: 1.164e-05
```

predicted beta0, beta1 and beta2 are respectively 2.1305, 1.4396 and 1.0097, compared to 2, 2, 0.3.
The H0 for beta1 can be rejected since its p value is smaller than 0.05.

####Q15


```r
attach(Boston)
fit.all <- lm(crim ~ ., data = Boston)
summary(fit.all)
```

```
## 
## Call:
## lm(formula = crim ~ ., data = Boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.924 -2.120 -0.353  1.019 75.051 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  17.033228   7.234903   2.354 0.018949 *  
## zn            0.044855   0.018734   2.394 0.017025 *  
## indus        -0.063855   0.083407  -0.766 0.444294    
## chas         -0.749134   1.180147  -0.635 0.525867    
## nox         -10.313535   5.275536  -1.955 0.051152 .  
## rm            0.430131   0.612830   0.702 0.483089    
## age           0.001452   0.017925   0.081 0.935488    
## dis          -0.987176   0.281817  -3.503 0.000502 ***
## rad           0.588209   0.088049   6.680 6.46e-11 ***
## tax          -0.003780   0.005156  -0.733 0.463793    
## ptratio      -0.271081   0.186450  -1.454 0.146611    
## black        -0.007538   0.003673  -2.052 0.040702 *  
## lstat         0.126211   0.075725   1.667 0.096208 .  
## medv         -0.198887   0.060516  -3.287 0.001087 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.439 on 492 degrees of freedom
## Multiple R-squared:  0.454,	Adjusted R-squared:  0.4396 
## F-statistic: 31.47 on 13 and 492 DF,  p-value: < 2.2e-16
```


```r
cor(Boston[-c(1, 4)])
```

```
##                 zn      indus        nox         rm        age        dis
## zn       1.0000000 -0.5338282 -0.5166037  0.3119906 -0.5695373  0.6644082
## indus   -0.5338282  1.0000000  0.7636514 -0.3916759  0.6447785 -0.7080270
## nox     -0.5166037  0.7636514  1.0000000 -0.3021882  0.7314701 -0.7692301
## rm       0.3119906 -0.3916759 -0.3021882  1.0000000 -0.2402649  0.2052462
## age     -0.5695373  0.6447785  0.7314701 -0.2402649  1.0000000 -0.7478805
## dis      0.6644082 -0.7080270 -0.7692301  0.2052462 -0.7478805  1.0000000
## rad     -0.3119478  0.5951293  0.6114406 -0.2098467  0.4560225 -0.4945879
## tax     -0.3145633  0.7207602  0.6680232 -0.2920478  0.5064556 -0.5344316
## ptratio -0.3916785  0.3832476  0.1889327 -0.3555015  0.2615150 -0.2324705
## black    0.1755203 -0.3569765 -0.3800506  0.1280686 -0.2735340  0.2915117
## lstat   -0.4129946  0.6037997  0.5908789 -0.6138083  0.6023385 -0.4969958
## medv     0.3604453 -0.4837252 -0.4273208  0.6953599 -0.3769546  0.2499287
##                rad        tax    ptratio      black      lstat       medv
## zn      -0.3119478 -0.3145633 -0.3916785  0.1755203 -0.4129946  0.3604453
## indus    0.5951293  0.7207602  0.3832476 -0.3569765  0.6037997 -0.4837252
## nox      0.6114406  0.6680232  0.1889327 -0.3800506  0.5908789 -0.4273208
## rm      -0.2098467 -0.2920478 -0.3555015  0.1280686 -0.6138083  0.6953599
## age      0.4560225  0.5064556  0.2615150 -0.2735340  0.6023385 -0.3769546
## dis     -0.4945879 -0.5344316 -0.2324705  0.2915117 -0.4969958  0.2499287
## rad      1.0000000  0.9102282  0.4647412 -0.4444128  0.4886763 -0.3816262
## tax      0.9102282  1.0000000  0.4608530 -0.4418080  0.5439934 -0.4685359
## ptratio  0.4647412  0.4608530  1.0000000 -0.1773833  0.3740443 -0.5077867
## black   -0.4444128 -0.4418080 -0.1773833  1.0000000 -0.3660869  0.3334608
## lstat    0.4886763  0.5439934  0.3740443 -0.3660869  1.0000000 -0.7376627
## medv    -0.3816262 -0.4685359 -0.5077867  0.3334608 -0.7376627  1.0000000
```


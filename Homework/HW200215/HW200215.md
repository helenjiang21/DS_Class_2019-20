---
title: "HW200215"
output: 
  html_document:
    keep_md: TRUE
    toc: TRUE
    toc_float: TRUE
---



## Chapter 5

###Q2

####g)


```r
x <- 1:100000
plot(x, 1 - (1 - 1/x)^x)
```

![](HW200215_files/figure-html/unnamed-chunk-1-1.png)<!-- -->

####h)


```r
store <- rep(NA, 10000)
for (i in 1:10000) {
    store[i] <- sum(sample(1:100, rep = TRUE) == 4) >0
}
mean(store)
```

```
## [1] 0.626
```

the limit of (1-x/n)^n = e^x. in this case it appoarches 1-1/e equals 0.6332

###Q5

####a) logistic regression


```r
attach(Default)
fit_glm <- glm(default ~ income + balance, data = Default, family = "binomial")
summary(fit_glm)
```

```
## 
## Call:
## glm(formula = default ~ income + balance, family = "binomial", 
##     data = Default)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4725  -0.1444  -0.0574  -0.0211   3.7245  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***
## income       2.081e-05  4.985e-06   4.174 2.99e-05 ***
## balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 2920.6  on 9999  degrees of freedom
## Residual deviance: 1579.0  on 9997  degrees of freedom
## AIC: 1585
## 
## Number of Fisher Scoring iterations: 8
```

####b) validation set

i) split into sets

```r
train1 <- sample(dim(Default)[1], dim(Default)[1] / 2)
validation1 <- Default[-train1, ]
```

ii)regression

```r
fit_glm1 <- glm(default ~ income + balance, data = Default, subset = train1, family = "binomial")
summary(fit_glm1)
```

```
## 
## Call:
## glm(formula = default ~ income + balance, family = "binomial", 
##     data = Default, subset = train1)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4965  -0.1291  -0.0489  -0.0179   3.2079  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.205e+01  6.602e-01 -18.244  < 2e-16 ***
## income       2.145e-05  7.340e-06   2.923  0.00347 ** 
## balance      5.871e-03  3.414e-04  17.196  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1416.27  on 4999  degrees of freedom
## Residual deviance:  732.02  on 4997  degrees of freedom
## AIC: 738.02
## 
## Number of Fisher Scoring iterations: 8
```

iii) predict using validation

```r
probs1 <- predict(fit_glm1, validation1, type ="response")
pred_glm1 <- rep("No", length(probs1))
pred_glm1[probs1 > 0.5] <- "Yes"
error1 <- mean(pred_glm1 != validation1$default)
error1
```

```
## [1] 0.0266
```

####c) repeating b using different validation sets


```r
set.seed(2)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
validation <- Default[-train, ]
fit_glm0 <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
probs <- predict(fit_glm0, validation, type ="response")
pred_glm <- rep("No", length(probs))
pred_glm[probs > 0.5] <- "Yes"
error <- mean(pred_glm != validation$default)
error
```

```
## [1] 0.0238
```


```r
set.seed(3)
train <- sample(dim(Default)[1], dim(Default)[1] / 2)
validation <- Default[-train, ]
fit_glm <- glm(default ~ income + balance, data = Default, subset = train, family = "binomial")
probs <- predict(fit_glm, validation, type ="response")
pred_glm <- rep("No", length(probs))
pred_glm[probs > 0.5] <- "Yes"
error <- mean(pred_glm != validation$default)
error
```

```
## [1] 0.0264
```

####d) including student


```r
trains <- sample(dim(Default)[1], dim(Default)[1] / 2)
validations <- Default[-trains, ]
fit_glms <- glm(default ~ income + balance + student, data = Default, subset = train, family = "binomial")
probs <- predict(fit_glms, validations, type ="response")
pred_glms <- rep("No", length(probs))
pred_glms[probs > 0.5] <- "Yes"
errors <- mean(pred_glms != validation$default)
errors
```

```
## [1] 0.046
```
it increases the error rate.

###Q6

####a) logistic


```r
attach(Default)
```

```
## The following objects are masked from Default (pos = 3):
## 
##     balance, default, income, student
```

```r
fit_glmb <- glm(default ~ income + balance, data = Default, family = "binomial")
coef(summary(fit_glmb))
```

```
##                  Estimate   Std. Error    z value      Pr(>|z|)
## (Intercept) -1.154047e+01 4.347564e-01 -26.544680 2.958355e-155
## income       2.080898e-05 4.985167e-06   4.174178  2.990638e-05
## balance      5.647103e-03 2.273731e-04  24.836280 3.638120e-136
```

####b) bootstrap function


```r
boot.fn <- function(data, index) {
  fit <- glm(default ~ income + balance, data = data, family = "binomial", subset = index)
  return(coef(fit))
}
```

####c) perform


```r
boot(Default, boot.fn, 1000)
```

```
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = Default, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##          original        bias     std. error
## t1* -1.154047e+01 -4.105735e-02 4.384554e-01
## t2*  2.080898e-05  2.041719e-07 4.863868e-06
## t3*  5.647103e-03  1.955983e-05 2.312729e-04
```

####d) comparison
kinda similar

###Q7

####a) logistic


```r
attach(Weekly)
fit_glmw <- glm(Direction ~ Lag1 + Lag2, data = Weekly, family = "binomial")
summary(fit_glmw)
```

```
## 
## Call:
## glm(formula = Direction ~ Lag1 + Lag2, family = "binomial", data = Weekly)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.623  -1.261   1.001   1.083   1.506  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.22122    0.06147   3.599 0.000319 ***
## Lag1        -0.03872    0.02622  -1.477 0.139672    
## Lag2         0.06025    0.02655   2.270 0.023232 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1496.2  on 1088  degrees of freedom
## Residual deviance: 1488.2  on 1086  degrees of freedom
## AIC: 1494.2
## 
## Number of Fisher Scoring iterations: 4
```

####b) all but not the first observation


```r
fit_glmw1 <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-1, ], family = "binomial")
summary(fit_glmw1)
```

```
## 
## Call:
## glm(formula = Direction ~ Lag1 + Lag2, family = "binomial", data = Weekly[-1, 
##     ])
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6258  -1.2617   0.9999   1.0819   1.5071  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.22324    0.06150   3.630 0.000283 ***
## Lag1        -0.03843    0.02622  -1.466 0.142683    
## Lag2         0.06085    0.02656   2.291 0.021971 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1494.6  on 1087  degrees of freedom
## Residual deviance: 1486.5  on 1085  degrees of freedom
## AIC: 1492.5
## 
## Number of Fisher Scoring iterations: 4
```

####c) using b to predict the first


```r
predict(fit_glmw1, Weekly[1, ], type = "response") > 0.5
```

```
##    1 
## TRUE
```

```r
Weekly[1,]
```

```
##   Year  Lag1  Lag2   Lag3   Lag4   Lag5   Volume Today Direction
## 1 1990 0.816 1.572 -3.936 -0.229 -3.484 0.154976 -0.27      Down
```
it predicts up, which is incorrect since the actual direction is down.

####d) loocv loop


```r
errorw <- rep(0, dim(Weekly)[1])
for (i in 1:dim(Weekly)[1]) {
    fit_glmw <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-i, ],  family = "binomial")
    pred_up <- predict(fit_glmw, Weekly[i, ], type = "response") > 0.5
    true_up <- Weekly[i, ]$Direction == "Up"
    if (pred_up != true_up)
        errorw[i] <- 1
}
```

####e) error


```r
mean(errorw)
```

```
## [1] 0.4499541
```

###Q8

####a)


```r
set.seed(1)
y <- rnorm(100)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)
```
n is 100, p is 2. Y = X - X^2 + ??

####b) plot


```r
plot(x, y)
```

![](HW200215_files/figure-html/unnamed-chunk-19-1.png)<!-- -->
looks like second degree polynomial.

####c) LOOCV error

i) first degree

```r
set.seed(1)
Data <- data.frame(x, y)
fit_glmp1 <- glm(y ~ x)
cv.glm(Data, fit_glmp1)$delta[1]
```

```
## [1] 5.890979
```

ii) second degree

```r
fit_glmp2 <- glm(y ~ poly(x, 2))
cv.glm(Data, fit_glmp2)$delta[1]
```

```
## [1] 1.086596
```

iii) third degree

```r
fit_glmp3 <- glm(y ~ poly(x, 3))
cv.glm(Data, fit_glmp3)$delta[1]
```

```
## [1] 1.102585
```

iv) fourth

```r
fit_glmp4 <- glm(y ~ poly(x, 4))
cv.glm(Data, fit_glmp4)$delta[1]
```

```
## [1] 1.114772
```

####d) repeat using another random seed


```r
set.seed(8)
Data <- data.frame(x, y)
fit_glmp1 <- glm(y ~ x)
cv.glm(Data, fit_glmp1)$delta[1]
```

```
## [1] 5.890979
```

```r
fit_glmp2 <- glm(y ~ poly(x, 2))
cv.glm(Data, fit_glmp2)$delta[1]
```

```
## [1] 1.086596
```

```r
fit_glmp3 <- glm(y ~ poly(x, 3))
cv.glm(Data, fit_glmp3)$delta[1]
```

```
## [1] 1.102585
```

```r
fit_glmp4 <- glm(y ~ poly(x, 4))
cv.glm(Data, fit_glmp4)$delta[1]
```

```
## [1] 1.114772
```
the errors are the same.

####e) smallest error

Quadratic fit has the smallest error, corresponding to the equation.

####f) significance tests


```r
summary(fit_glmp1)
```

```
## 
## Call:
## glm(formula = y ~ x)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -7.3469  -0.9275   0.8028   1.5608   4.3974  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -1.8185     0.2364  -7.692 1.14e-11 ***
## x             0.2430     0.2479   0.981    0.329    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 5.580018)
## 
##     Null deviance: 552.21  on 99  degrees of freedom
## Residual deviance: 546.84  on 98  degrees of freedom
## AIC: 459.69
## 
## Number of Fisher Scoring iterations: 2
```

```r
summary(fit_glmp2)
```

```
## 
## Call:
## glm(formula = y ~ poly(x, 2))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.89884  -0.53765   0.04135   0.61490   2.73607  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -1.8277     0.1032 -17.704   <2e-16 ***
## poly(x, 2)1   2.3164     1.0324   2.244   0.0271 *  
## poly(x, 2)2 -21.0586     1.0324 -20.399   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 1.06575)
## 
##     Null deviance: 552.21  on 99  degrees of freedom
## Residual deviance: 103.38  on 97  degrees of freedom
## AIC: 295.11
## 
## Number of Fisher Scoring iterations: 2
```

```r
summary(fit_glmp3)
```

```
## 
## Call:
## glm(formula = y ~ poly(x, 3))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.87250  -0.53881   0.02862   0.59383   2.74350  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -1.8277     0.1037 -17.621   <2e-16 ***
## poly(x, 3)1   2.3164     1.0372   2.233   0.0279 *  
## poly(x, 3)2 -21.0586     1.0372 -20.302   <2e-16 ***
## poly(x, 3)3  -0.3048     1.0372  -0.294   0.7695    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 1.075883)
## 
##     Null deviance: 552.21  on 99  degrees of freedom
## Residual deviance: 103.28  on 96  degrees of freedom
## AIC: 297.02
## 
## Number of Fisher Scoring iterations: 2
```

```r
summary(fit_glmp4)
```

```
## 
## Call:
## glm(formula = y ~ poly(x, 4))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.8914  -0.5244   0.0749   0.5932   2.7796  
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -1.8277     0.1041 -17.549   <2e-16 ***
## poly(x, 4)1   2.3164     1.0415   2.224   0.0285 *  
## poly(x, 4)2 -21.0586     1.0415 -20.220   <2e-16 ***
## poly(x, 4)3  -0.3048     1.0415  -0.293   0.7704    
## poly(x, 4)4  -0.4926     1.0415  -0.473   0.6373    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 1.084654)
## 
##     Null deviance: 552.21  on 99  degrees of freedom
## Residual deviance: 103.04  on 95  degrees of freedom
## AIC: 298.78
## 
## Number of Fisher Scoring iterations: 2
```

the third and fourth degree of x are not significant.

###Q9

####a) computing ??^


```r
attach(Boston)
u <- mean(medv)
u
```

```
## [1] 22.53281
```

####b) standard error


```r
se <- sd(medv) / sqrt(dim(Boston)[1])
se
```

```
## [1] 0.4088611
```

####c) estimate se using bootstrap


```r
set.seed(1)
boot_fn <- function(data, index) {
    u <- mean(data[index])
    return (u)
}
boot(medv, boot_fn, 1000)
```

```
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = medv, statistic = boot_fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##     original      bias    std. error
## t1* 22.53281 0.007650791   0.4106622
```

se here is 0.4107, close to 0.4089 in b).

####d) confidence interval


```r
CI <- c(22.53 - 2 * 0.4119, 22.53 + 2 * 0.4119)
CI
```

```
## [1] 21.7062 23.3538
```



```r
t.test(medv)
```

```
## 
## 	One Sample t-test
## 
## data:  medv
## t = 55.111, df = 505, p-value < 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.72953 23.33608
## sample estimates:
## mean of x 
##  22.53281
```
(`confint()` only work for fitted model object)
very close.

####e) median


```r
med <- median(medv)
med
```

```
## [1] 21.2
```

####f) bootstrap on median for se


```r
boot.fn <- function(data, index) {
    med <- median(data[index])
    return (med)
}
boot(medv, boot.fn, 1000)
```

```
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = medv, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##     original  bias    std. error
## t1*     21.2 -0.0386   0.3770241
```

####g) ten precentile


```r
tentile <- quantile(medv, c(0.1))
tentile
```

```
##   10% 
## 12.75
```

####h) se of tentile


```r
boot.fn <- function(data, index) {
    tentile <- quantile(data[index], c(0.1))
    return (tentile)
}
boot(medv, boot.fn, 1000)
```

```
## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = medv, statistic = boot.fn, R = 1000)
## 
## 
## Bootstrap Statistics :
##     original  bias    std. error
## t1*    12.75  0.0186   0.4925766
```
very close again.
